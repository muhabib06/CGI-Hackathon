üöÄ API Mock Server Generator (KI-gest√ºtzt)

Dieses Projekt demonstriert einen automatisierten Workflow zur Erstellung eines funktionsf√§higen API-Mock-Servers (mit FastAPI) und der zugeh√∂rigen Pytest-Testf√§lle, basierend auf einer einzigen textuellen Anforderung (dem "Topic"). Die gesamte Generierung von OpenAPI-Spezifikation, Testdaten, Mock-Server-Code und Test-Code wird durch einen LLM-Agenten gesteuert.

üõ†Ô∏è Komponenten des Systems

Das System besteht aus mehreren aufeinander aufbauenden Python-Skripten, die den gesamten Generierungs- und Validierungsprozess steuern:

Datei

Rolle

Beschreibung

main.py

HAUPT-CONTROLLER

Startet den gesamten Workflow. Steuert den Dialog (topic.py), veranlasst die KI-Generierung (OpenAPI, Testdaten) und ruft die Code-Generatoren auf.

topic.py

REQUIREMENTS-ENGINEER

F√ºhrt einen interaktiven Dialog mit dem Benutzer, um das API-Thema zu sch√§rfen und auf Plausibilit√§t zu pr√ºfen, bevor die Generierung beginnt.

prompts.py

PROMPT-BIBLIOTHEK

Enth√§lt alle System- und User-Prompts, die f√ºr die Kommunikation mit dem LLM (Generierung von Spec, Testdaten, Validierung) verwendet werden.

testdata_validator.py

VALIDATOR

Pr√ºft die generierten Testdaten (testdata.json) erneut durch einen LLM, um die Einhaltung der 5 geforderten Negativ-/Positiv-Szenarien sicherzustellen.

mock_server_builder.py

SERVER-GENERATOR

Liest die finale openapi_definition.json und testdata.json ein und generiert daraus das lauff√§hige FastAPI-Mock-Server-Skript (mock_server.py).

generate_tests.py

TEST-GENERATOR

Liest testdata.json und generiert daraus die Pytest-Integrationstests (test_mock_api.py) f√ºr die CRUD-Operationen.

mock_server.py

GENERIERTER SERVER

Der fertige FastAPI-Mock-Server-Code.

test_mock_api.py

GENERIERTE TESTS

Die Pytest-Tests, um den mock_server.py zu √ºberpr√ºfen.

openapi_definition.json

GENERIERTE SPEZIFIKATION

Die finale OpenAPI 3.0 (oder 3.1) Spezifikation.

testdata.json

GENERIERTE DATEN

Testdatensatz f√ºr den Mock-Server und die Tests.

‚öôÔ∏è Voraussetzungen

Um das Projekt ausf√ºhren zu k√∂nnen, m√ºssen folgende Voraussetzungen erf√ºllt sein:

Python 3.x

Abh√§ngigkeiten: Alle ben√∂tigten Python-Pakete (z.B. fastapi, uvicorn, requests, pytest, pydantic, termcolor) m√ºssen installiert sein.

pip install fastapi uvicorn requests pytest pydantic termcolor


API-Token: Sie ben√∂tigen einen API-Token f√ºr den LLM-Service (im Code als IONOS_API_TOKEN referenziert). Dieser muss als Umgebungsvariable gesetzt werden:

export IONOS_API_TOKEN="<Ihr-Token-hier>"


üöÄ Workflow (Schritt-f√ºr-Schritt)

Phase 1: Generierung und Validierung

Start des Workflows:
F√ºhren Sie das Hauptskript aus. Dies startet den interaktiven Modus.

python main.py


Interaktive Themenkl√§rung:
Das Skript fragt nach Ihrer API-Idee und f√ºhrt Sie durch eine Schleife zur Sch√§rfung des Scopes, unterst√ºtzt durch den REQUIREMENTS-ENGINEER (topic.py).

LLM-Generierung:
Das LLM generiert die openapi_definition.json und die testdata.json.

Validierung:
Die generierten Testdaten werden automatisch durch den VALIDATOR (testdata_validator.py) validiert, um die Qualit√§t des generierten Inhalts sicherzustellen.

Code-Generierung:
Anschlie√üend werden der Mock-Server (mock_server.py) und die Testdatei (test_mock_api.py) generiert.

Phase 2: Test und Nutzung

Mock-Server starten:
F√ºhren Sie den generierten Mock-Server aus.

python mock_server.py


Der Server ist nun unter http://127.0.0.1:8000 verf√ºgbar. Die Swagger UI-Dokumentation finden Sie unter http://127.0.0.1:8000/docs.

Tests ausf√ºhren:
√ñffnen Sie ein zweites Terminalfenster und f√ºhren Sie die generierten Pytest-Tests aus. Diese Tests kommunizieren direkt mit dem laufenden Mock-Server und pr√ºfen die gesamte CRUD-Funktionalit√§t.

pytest test_mock_api.py


Analyse-Modus (Optional):
Wenn Sie eine bereits vorhandene OpenAPI-Spezifikation (z.B. jira_like_openapi.json) verwenden m√∂chten, starten Sie das Skript im Analyse-Modus, um neue Testdaten, den Mock-Server und die Tests zu generieren:

python main.py --analyze jira_like_openapi.json
